{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Required Library/Dataset**"
      ],
      "metadata": {
        "id": "PzJD1axfMJ8i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_FbL_P8LruC",
        "outputId": "88715d1b-ee06-4d4c-e186-c9544a465f8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MobileNetV1-Optimization-for-CIFAR10'...\n",
            "remote: Enumerating objects: 115, done.\u001b[K\n",
            "remote: Counting objects: 100% (115/115), done.\u001b[K\n",
            "remote: Compressing objects: 100% (103/103), done.\u001b[K\n",
            "remote: Total 115 (delta 35), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (115/115), 23.41 MiB | 14.96 MiB/s, done.\n",
            "Resolving deltas: 100% (35/35), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Song-Joo-Young/MobileNetV1-Optimization-for-CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('MobileNetV1-Optimization-for-CIFAR10')"
      ],
      "metadata": {
        "id": "IMCIGe6VN4r_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/MobileNetV1-Optimization-for-CIFAR10/models')"
      ],
      "metadata": {
        "id": "JtDxVEguQbke"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Optimizer\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Current GPU Index:\", torch.cuda.current_device())\n",
        "    print(\"Current GPU Name:\", torch.cuda.get_device_name(torch.cuda.current_device()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G73qgrZeL1KQ",
        "outputId": "df9f645f-9be2-4772-bf02-0478c1f55e9d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current GPU Index: 0\n",
            "Current GPU Name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR-10 Dataset\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Pad(4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32),\n",
        "    transforms.ToTensor()])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./cifar_10data/',\n",
        "                                 train=True,\n",
        "                                 transform=transform,\n",
        "                                 download=True)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root='./cifar_10data/',\n",
        "                                train=False,\n",
        "                                transform=transforms.ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsxwPYdJL1Me",
        "outputId": "27822afb-9669-44a9-8b81-1703f4011999"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar_10data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:01<00:00, 98248806.85it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./cifar_10data/cifar-10-python.tar.gz to ./cifar_10data/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fvcore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzJn8EeaNYGy",
        "outputId": "a29e6e0e-8d7c-4a50-aa75-76449863b4c4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m393.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore) (1.23.5)\n",
            "Collecting yacs>=0.1.6 (from fvcore)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore) (6.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fvcore) (4.66.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from fvcore) (2.4.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from fvcore) (9.4.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fvcore) (0.9.0)\n",
            "Collecting iopath>=0.1.7 (from fvcore)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from iopath>=0.1.7->fvcore) (4.5.0)\n",
            "Collecting portalocker (from iopath>=0.1.7->fvcore)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Building wheels for collected packages: fvcore, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=58d7e581de4792eafc2bf448107ed05f7ad8223cc727a69f604afca6a8c55d1d\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31532 sha256=cd04ea2877a65d1a130d057926cc613f37c325a588c19d41108c5b579210ce51\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
            "Successfully built fvcore iopath\n",
            "Installing collected packages: yacs, portalocker, iopath, fvcore\n",
            "Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-2.8.2 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "from fvcore.nn import FlopCountAnalysis"
      ],
      "metadata": {
        "id": "JuE8sk6LNbYa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Baseline MobileNet**\n",
        "* **Model**\n",
        "  * from: https://github.com/kuangliu/pytorch-cifar/blob/master/models/mobilenet.py\n",
        "* **Best accuracy** : [Test set] Average loss: 0.0056, Accuracy: 8426/10000 (84.26%)\n",
        "* **FLOPS** : 48,412,672\n",
        "\n",
        "* **hyperparameter**\n",
        "  * lr=0.03\n",
        "  * weight_decay=5e-4\n",
        "  * batch size = 100\n",
        "  * epoch = 100\n",
        "  * training time : 3484.9894 sec\n",
        "\n",
        "* **optimizer**\n",
        "  * SGD\n",
        "\n",
        "* **Data augmentation**\n",
        "  *   \n",
        "          transforms.Pad(4),\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          transforms.RandomCrop(32),\n",
        "          transforms.ToTensor()"
      ],
      "metadata": {
        "id": "tWgMCZUEL7YH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from models.Baseline_MobileNetV1 import MobileNet\n",
        "model = MobileNet().to(device)\n",
        "\n",
        "print(\"MobileNetV1 torchsummary\")\n",
        "summary(model, (3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFaxbFrML1Oo",
        "outputId": "ea046672-8cf4-4027-a7f5-5cfdb9634087"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MobileNetV1 torchsummary\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]             864\n",
            "       BatchNorm2d-2           [-1, 32, 32, 32]              64\n",
            "            Conv2d-3           [-1, 32, 32, 32]             288\n",
            "       BatchNorm2d-4           [-1, 32, 32, 32]              64\n",
            "            Conv2d-5           [-1, 64, 32, 32]           2,048\n",
            "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
            "             Block-7           [-1, 64, 32, 32]               0\n",
            "            Conv2d-8           [-1, 64, 16, 16]             576\n",
            "       BatchNorm2d-9           [-1, 64, 16, 16]             128\n",
            "           Conv2d-10          [-1, 128, 16, 16]           8,192\n",
            "      BatchNorm2d-11          [-1, 128, 16, 16]             256\n",
            "            Block-12          [-1, 128, 16, 16]               0\n",
            "           Conv2d-13          [-1, 128, 16, 16]           1,152\n",
            "      BatchNorm2d-14          [-1, 128, 16, 16]             256\n",
            "           Conv2d-15          [-1, 128, 16, 16]          16,384\n",
            "      BatchNorm2d-16          [-1, 128, 16, 16]             256\n",
            "            Block-17          [-1, 128, 16, 16]               0\n",
            "           Conv2d-18            [-1, 128, 8, 8]           1,152\n",
            "      BatchNorm2d-19            [-1, 128, 8, 8]             256\n",
            "           Conv2d-20            [-1, 256, 8, 8]          32,768\n",
            "      BatchNorm2d-21            [-1, 256, 8, 8]             512\n",
            "            Block-22            [-1, 256, 8, 8]               0\n",
            "           Conv2d-23            [-1, 256, 8, 8]           2,304\n",
            "      BatchNorm2d-24            [-1, 256, 8, 8]             512\n",
            "           Conv2d-25            [-1, 256, 8, 8]          65,536\n",
            "      BatchNorm2d-26            [-1, 256, 8, 8]             512\n",
            "            Block-27            [-1, 256, 8, 8]               0\n",
            "           Conv2d-28            [-1, 256, 4, 4]           2,304\n",
            "      BatchNorm2d-29            [-1, 256, 4, 4]             512\n",
            "           Conv2d-30            [-1, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-31            [-1, 512, 4, 4]           1,024\n",
            "            Block-32            [-1, 512, 4, 4]               0\n",
            "           Conv2d-33            [-1, 512, 4, 4]           4,608\n",
            "      BatchNorm2d-34            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-35            [-1, 512, 4, 4]         262,144\n",
            "      BatchNorm2d-36            [-1, 512, 4, 4]           1,024\n",
            "            Block-37            [-1, 512, 4, 4]               0\n",
            "           Conv2d-38            [-1, 512, 4, 4]           4,608\n",
            "      BatchNorm2d-39            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-40            [-1, 512, 4, 4]         262,144\n",
            "      BatchNorm2d-41            [-1, 512, 4, 4]           1,024\n",
            "            Block-42            [-1, 512, 4, 4]               0\n",
            "           Conv2d-43            [-1, 512, 4, 4]           4,608\n",
            "      BatchNorm2d-44            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-45            [-1, 512, 4, 4]         262,144\n",
            "      BatchNorm2d-46            [-1, 512, 4, 4]           1,024\n",
            "            Block-47            [-1, 512, 4, 4]               0\n",
            "           Conv2d-48            [-1, 512, 4, 4]           4,608\n",
            "      BatchNorm2d-49            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-50            [-1, 512, 4, 4]         262,144\n",
            "      BatchNorm2d-51            [-1, 512, 4, 4]           1,024\n",
            "            Block-52            [-1, 512, 4, 4]               0\n",
            "           Conv2d-53            [-1, 512, 4, 4]           4,608\n",
            "      BatchNorm2d-54            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-55            [-1, 512, 4, 4]         262,144\n",
            "      BatchNorm2d-56            [-1, 512, 4, 4]           1,024\n",
            "            Block-57            [-1, 512, 4, 4]               0\n",
            "           Conv2d-58            [-1, 512, 2, 2]           4,608\n",
            "      BatchNorm2d-59            [-1, 512, 2, 2]           1,024\n",
            "           Conv2d-60           [-1, 1024, 2, 2]         524,288\n",
            "      BatchNorm2d-61           [-1, 1024, 2, 2]           2,048\n",
            "            Block-62           [-1, 1024, 2, 2]               0\n",
            "           Conv2d-63           [-1, 1024, 2, 2]           9,216\n",
            "      BatchNorm2d-64           [-1, 1024, 2, 2]           2,048\n",
            "           Conv2d-65           [-1, 1024, 2, 2]       1,048,576\n",
            "      BatchNorm2d-66           [-1, 1024, 2, 2]           2,048\n",
            "            Block-67           [-1, 1024, 2, 2]               0\n",
            "           Linear-68                   [-1, 10]          10,250\n",
            "================================================================\n",
            "Total params: 3,217,226\n",
            "Trainable params: 3,217,226\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 7.97\n",
            "Params size (MB): 12.27\n",
            "Estimated Total Size (MB): 20.25\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.randn(1, 3, 32, 32).to(device)\n",
        "\n",
        "flops = FlopCountAnalysis(model, inputs)\n",
        "print('Total FLOPS :', flops.total())  # Total FLOPS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3-FTrf5Qzq0",
        "outputId": "0514f118-63c0-4ee2-a4d2-a3f0f0c7a558"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add_ encountered 27 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::avg_pool2d encountered 1 time(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total FLOPS : 48412672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "model = MobileNet().to(device)\n",
        "\n",
        "model_path = '/content/MobileNetV1-Optimization-for-CIFAR10/best_weights/MobileNetV1_best_model_epoch_90.pkt'\n",
        "model.load_state_dict(torch.load(model_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfIUZYBrQ-Eg",
        "outputId": "562a2194-7431-4e3c-d5fd-1123470e73b3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_loss, correct, total = 0, 0, 0\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)\n",
        "with torch.no_grad():  #using context manager\n",
        "    for images, labels in test_loader :\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        output = model(images)\n",
        "        test_loss += loss_function(output, labels).item()\n",
        "\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "\n",
        "        total += labels.size(0)\n",
        "\n",
        "print('[Test set] Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss /total, correct, total,\n",
        "        100. * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7o9Lv5xSJcD",
        "outputId": "e0fa64f4-07f0-4713-d387-059fa9fa0839"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Test set] Average loss: 0.0056, Accuracy: 8426/10000 (84.26%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **MobileNetV2**\n",
        "* **Model**\n",
        "  * MobileNetV2 from: https://github.com/chenhang98/mobileNet-v2_cifar10/blob/master\n",
        "* **Best accuracy** : [Test set] Average loss: 0.0040, Accuracy: 8735/10000 (87.35%)\n",
        "* **FLOPS** : 319,015,424\n",
        "\n",
        "\n",
        "* **hyperparameter**\n",
        "  * lr=0.1\n",
        "  * weight_decay=4e-5\n",
        "  * batch size = 100\n",
        "  * momentum = 0.9\n",
        "  * epoch = 25\n",
        "  * training time : 3439.5674\n",
        "\n",
        "* **optimizer**\n",
        "  * SGD\n",
        "\n",
        "* **Data augmentation**\n",
        "  *   \n",
        "          transforms.Pad(4),\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          transforms.RandomCrop(32),\n",
        "          transforms.ToTensor()"
      ],
      "metadata": {
        "id": "NUDY3mvcSPBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from models.MobileNetV2 import MobileNetV2\n",
        "model = MobileNetV2(10, alpha = 1).to(device)\n",
        "\n",
        "print(\"MobileNetV2 torchsummary\")\n",
        "summary(model, (3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrULM77kSU-3",
        "outputId": "2326aea9-fce5-4578-f8f8-04ceaf114cea"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MobileNetV2 torchsummary\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]             864\n",
            "       BatchNorm2d-2           [-1, 32, 32, 32]              64\n",
            "            Conv2d-3           [-1, 32, 32, 32]           1,024\n",
            "       BatchNorm2d-4           [-1, 32, 32, 32]              64\n",
            "            Conv2d-5           [-1, 32, 32, 32]             288\n",
            "       BatchNorm2d-6           [-1, 32, 32, 32]              64\n",
            "            Conv2d-7           [-1, 16, 32, 32]             512\n",
            "       BatchNorm2d-8           [-1, 16, 32, 32]              32\n",
            "         BaseBlock-9           [-1, 16, 32, 32]               0\n",
            "           Conv2d-10           [-1, 96, 32, 32]           1,536\n",
            "      BatchNorm2d-11           [-1, 96, 32, 32]             192\n",
            "           Conv2d-12           [-1, 96, 32, 32]             864\n",
            "      BatchNorm2d-13           [-1, 96, 32, 32]             192\n",
            "           Conv2d-14           [-1, 24, 32, 32]           2,304\n",
            "      BatchNorm2d-15           [-1, 24, 32, 32]              48\n",
            "        BaseBlock-16           [-1, 24, 32, 32]               0\n",
            "           Conv2d-17          [-1, 144, 32, 32]           3,456\n",
            "      BatchNorm2d-18          [-1, 144, 32, 32]             288\n",
            "           Conv2d-19          [-1, 144, 32, 32]           1,296\n",
            "      BatchNorm2d-20          [-1, 144, 32, 32]             288\n",
            "           Conv2d-21           [-1, 24, 32, 32]           3,456\n",
            "      BatchNorm2d-22           [-1, 24, 32, 32]              48\n",
            "        BaseBlock-23           [-1, 24, 32, 32]               0\n",
            "           Conv2d-24          [-1, 144, 32, 32]           3,456\n",
            "      BatchNorm2d-25          [-1, 144, 32, 32]             288\n",
            "           Conv2d-26          [-1, 144, 32, 32]           1,296\n",
            "      BatchNorm2d-27          [-1, 144, 32, 32]             288\n",
            "           Conv2d-28           [-1, 32, 32, 32]           4,608\n",
            "      BatchNorm2d-29           [-1, 32, 32, 32]              64\n",
            "        BaseBlock-30           [-1, 32, 32, 32]               0\n",
            "           Conv2d-31          [-1, 192, 32, 32]           6,144\n",
            "      BatchNorm2d-32          [-1, 192, 32, 32]             384\n",
            "           Conv2d-33          [-1, 192, 32, 32]           1,728\n",
            "      BatchNorm2d-34          [-1, 192, 32, 32]             384\n",
            "           Conv2d-35           [-1, 32, 32, 32]           6,144\n",
            "      BatchNorm2d-36           [-1, 32, 32, 32]              64\n",
            "        BaseBlock-37           [-1, 32, 32, 32]               0\n",
            "           Conv2d-38          [-1, 192, 32, 32]           6,144\n",
            "      BatchNorm2d-39          [-1, 192, 32, 32]             384\n",
            "           Conv2d-40          [-1, 192, 32, 32]           1,728\n",
            "      BatchNorm2d-41          [-1, 192, 32, 32]             384\n",
            "           Conv2d-42           [-1, 32, 32, 32]           6,144\n",
            "      BatchNorm2d-43           [-1, 32, 32, 32]              64\n",
            "        BaseBlock-44           [-1, 32, 32, 32]               0\n",
            "           Conv2d-45          [-1, 192, 32, 32]           6,144\n",
            "      BatchNorm2d-46          [-1, 192, 32, 32]             384\n",
            "           Conv2d-47          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-48          [-1, 192, 16, 16]             384\n",
            "           Conv2d-49           [-1, 64, 16, 16]          12,288\n",
            "      BatchNorm2d-50           [-1, 64, 16, 16]             128\n",
            "        BaseBlock-51           [-1, 64, 16, 16]               0\n",
            "           Conv2d-52          [-1, 384, 16, 16]          24,576\n",
            "      BatchNorm2d-53          [-1, 384, 16, 16]             768\n",
            "           Conv2d-54          [-1, 384, 16, 16]           3,456\n",
            "      BatchNorm2d-55          [-1, 384, 16, 16]             768\n",
            "           Conv2d-56           [-1, 64, 16, 16]          24,576\n",
            "      BatchNorm2d-57           [-1, 64, 16, 16]             128\n",
            "        BaseBlock-58           [-1, 64, 16, 16]               0\n",
            "           Conv2d-59          [-1, 384, 16, 16]          24,576\n",
            "      BatchNorm2d-60          [-1, 384, 16, 16]             768\n",
            "           Conv2d-61          [-1, 384, 16, 16]           3,456\n",
            "      BatchNorm2d-62          [-1, 384, 16, 16]             768\n",
            "           Conv2d-63           [-1, 64, 16, 16]          24,576\n",
            "      BatchNorm2d-64           [-1, 64, 16, 16]             128\n",
            "        BaseBlock-65           [-1, 64, 16, 16]               0\n",
            "           Conv2d-66          [-1, 384, 16, 16]          24,576\n",
            "      BatchNorm2d-67          [-1, 384, 16, 16]             768\n",
            "           Conv2d-68          [-1, 384, 16, 16]           3,456\n",
            "      BatchNorm2d-69          [-1, 384, 16, 16]             768\n",
            "           Conv2d-70           [-1, 64, 16, 16]          24,576\n",
            "      BatchNorm2d-71           [-1, 64, 16, 16]             128\n",
            "        BaseBlock-72           [-1, 64, 16, 16]               0\n",
            "           Conv2d-73          [-1, 384, 16, 16]          24,576\n",
            "      BatchNorm2d-74          [-1, 384, 16, 16]             768\n",
            "           Conv2d-75          [-1, 384, 16, 16]           3,456\n",
            "      BatchNorm2d-76          [-1, 384, 16, 16]             768\n",
            "           Conv2d-77           [-1, 96, 16, 16]          36,864\n",
            "      BatchNorm2d-78           [-1, 96, 16, 16]             192\n",
            "        BaseBlock-79           [-1, 96, 16, 16]               0\n",
            "           Conv2d-80          [-1, 576, 16, 16]          55,296\n",
            "      BatchNorm2d-81          [-1, 576, 16, 16]           1,152\n",
            "           Conv2d-82          [-1, 576, 16, 16]           5,184\n",
            "      BatchNorm2d-83          [-1, 576, 16, 16]           1,152\n",
            "           Conv2d-84           [-1, 96, 16, 16]          55,296\n",
            "      BatchNorm2d-85           [-1, 96, 16, 16]             192\n",
            "        BaseBlock-86           [-1, 96, 16, 16]               0\n",
            "           Conv2d-87          [-1, 576, 16, 16]          55,296\n",
            "      BatchNorm2d-88          [-1, 576, 16, 16]           1,152\n",
            "           Conv2d-89          [-1, 576, 16, 16]           5,184\n",
            "      BatchNorm2d-90          [-1, 576, 16, 16]           1,152\n",
            "           Conv2d-91           [-1, 96, 16, 16]          55,296\n",
            "      BatchNorm2d-92           [-1, 96, 16, 16]             192\n",
            "        BaseBlock-93           [-1, 96, 16, 16]               0\n",
            "           Conv2d-94          [-1, 576, 16, 16]          55,296\n",
            "      BatchNorm2d-95          [-1, 576, 16, 16]           1,152\n",
            "           Conv2d-96            [-1, 576, 8, 8]           5,184\n",
            "      BatchNorm2d-97            [-1, 576, 8, 8]           1,152\n",
            "           Conv2d-98            [-1, 160, 8, 8]          92,160\n",
            "      BatchNorm2d-99            [-1, 160, 8, 8]             320\n",
            "       BaseBlock-100            [-1, 160, 8, 8]               0\n",
            "          Conv2d-101            [-1, 960, 8, 8]         153,600\n",
            "     BatchNorm2d-102            [-1, 960, 8, 8]           1,920\n",
            "          Conv2d-103            [-1, 960, 8, 8]           8,640\n",
            "     BatchNorm2d-104            [-1, 960, 8, 8]           1,920\n",
            "          Conv2d-105            [-1, 160, 8, 8]         153,600\n",
            "     BatchNorm2d-106            [-1, 160, 8, 8]             320\n",
            "       BaseBlock-107            [-1, 160, 8, 8]               0\n",
            "          Conv2d-108            [-1, 960, 8, 8]         153,600\n",
            "     BatchNorm2d-109            [-1, 960, 8, 8]           1,920\n",
            "          Conv2d-110            [-1, 960, 8, 8]           8,640\n",
            "     BatchNorm2d-111            [-1, 960, 8, 8]           1,920\n",
            "          Conv2d-112            [-1, 160, 8, 8]         153,600\n",
            "     BatchNorm2d-113            [-1, 160, 8, 8]             320\n",
            "       BaseBlock-114            [-1, 160, 8, 8]               0\n",
            "          Conv2d-115            [-1, 960, 8, 8]         153,600\n",
            "     BatchNorm2d-116            [-1, 960, 8, 8]           1,920\n",
            "          Conv2d-117            [-1, 960, 8, 8]           8,640\n",
            "     BatchNorm2d-118            [-1, 960, 8, 8]           1,920\n",
            "          Conv2d-119            [-1, 320, 8, 8]         307,200\n",
            "     BatchNorm2d-120            [-1, 320, 8, 8]             640\n",
            "       BaseBlock-121            [-1, 320, 8, 8]               0\n",
            "          Conv2d-122           [-1, 1280, 8, 8]         409,600\n",
            "     BatchNorm2d-123           [-1, 1280, 8, 8]           2,560\n",
            "          Linear-124                   [-1, 10]          12,810\n",
            "================================================================\n",
            "Total params: 2,237,770\n",
            "Trainable params: 2,237,770\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 68.05\n",
            "Params size (MB): 8.54\n",
            "Estimated Total Size (MB): 76.60\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.randn(1, 3, 32, 32).to(device)\n",
        "\n",
        "flops = FlopCountAnalysis(model, inputs)\n",
        "print('Total FLOPS :', flops.total())  # Total FLOPS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2J2rnpeTu8s",
        "outputId": "f8db6bcf-1ba7-47e8-df15-5f579edc57d6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add encountered 22 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::avg_pool2d encountered 1 time(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total FLOPS : 26681344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "model = MobileNetV2(10, alpha = 1).to(device)\n",
        "\n",
        "model_path = '/content/MobileNetV1-Optimization-for-CIFAR10/best_weights/MobileNetV2_best_model_epoch_25.pkt'\n",
        "model.load_state_dict(torch.load(model_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeKnR7kBStG6",
        "outputId": "34458c46-0726-44c3-8883-f8ecd01028b1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_loss, correct, total = 0, 0, 0\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)\n",
        "with torch.no_grad():  #using context manager\n",
        "    for images, labels in test_loader :\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        output = model(images)\n",
        "        test_loss += loss_function(output, labels).item()\n",
        "\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "\n",
        "        total += labels.size(0)\n",
        "\n",
        "print('[Test set] Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss /total, correct, total,\n",
        "        100. * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IyVvJcdS2hF",
        "outputId": "f7439c88-1045-4e36-9ce6-a9d8e732bfaf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Test set] Average loss: 0.0040, Accuracy: 8735/10000 (87.35%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CustomMobileNet - Final version**\n",
        "* **Model**\n",
        "  * Architecture Adjustments\n",
        "    * cfg = [32, 32, 32, (64,2), 64, 64, 64, (128,2), 128, 128, 128, 128, 128, 128, 128, 128, (256,2), 256, 256, 256, (512,2), 512]\n",
        "    * Residual connection\n",
        "  * Hyperparameter Tuning\n",
        "  * Scheduler\n",
        "  * Data Augmentation Techniques\n",
        "    * Mix-up\n",
        "  * Regularization Strategies\n",
        "    * Drop out\n",
        "    * Weight initialization\n",
        "  \n",
        "* **Best accuracy** :\n",
        "  * Baseline : [Test set] Average loss: 0.0056, Accuracy: 8426/10000 (84.26%)\n",
        "  * CustomMobileNet : [Test set] Average loss: 0.0032, Accuracy: 9185/10000 (91.85%) **[ +7.59% ]**\n",
        "\n",
        "* **FLOPS** : 48,412,672 → 28,963,840 **[ -19,448,832 ]**\n",
        "* **Total parameters** : 3,217,226 → 1,002,218 **[ -2,215,008 ]**\n",
        "\n",
        "* **hyperparameter**\n",
        "  * lr=(0.1), 0.94 * epoch\n",
        "  * weight_decay=2.5e-3\n",
        "  * momentum=0.9\n",
        "  * batch size = 500\n",
        "  * epoch = 95 + 10 = 105\n",
        "  * training time : 3544.60\n",
        "\n",
        "* **optimizer**\n",
        "  * SGD\n",
        "\n",
        "* **Data augmentation**\n",
        "  * **mix-up(alpha = 1.0)**\n",
        "  * Reference: Facebookreseach mixup-cifar10 (https://github.com/facebookresearch/mixup-cifar10)\n",
        "  *   \n",
        "          transforms.Pad(4),\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          transforms.RandomCrop(32),\n",
        "          transforms.ToTensor()"
      ],
      "metadata": {
        "id": "Z2xO60wLL1Xe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from models.CustomMobileNet import CustomMobileNet\n",
        "model = CustomMobileNet().to(device)\n",
        "\n",
        "print(\"CustomMobileNet torchsummary\")\n",
        "summary(model, (3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mc2IVbqJL1sq",
        "outputId": "788f8d24-c57c-4c94-f443-7006c0977a04"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CustomMobileNet torchsummary\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             432\n",
            "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
            "            Conv2d-3           [-1, 16, 32, 32]             144\n",
            "       BatchNorm2d-4           [-1, 16, 32, 32]              32\n",
            "            Conv2d-5           [-1, 32, 32, 32]             512\n",
            "       BatchNorm2d-6           [-1, 32, 32, 32]              64\n",
            "            Conv2d-7           [-1, 32, 32, 32]             512\n",
            "       BatchNorm2d-8           [-1, 32, 32, 32]              64\n",
            "             Block-9           [-1, 32, 32, 32]               0\n",
            "           Conv2d-10           [-1, 32, 32, 32]             288\n",
            "      BatchNorm2d-11           [-1, 32, 32, 32]              64\n",
            "           Conv2d-12           [-1, 32, 32, 32]           1,024\n",
            "      BatchNorm2d-13           [-1, 32, 32, 32]              64\n",
            "            Block-14           [-1, 32, 32, 32]               0\n",
            "           Conv2d-15           [-1, 32, 32, 32]             288\n",
            "      BatchNorm2d-16           [-1, 32, 32, 32]              64\n",
            "           Conv2d-17           [-1, 32, 32, 32]           1,024\n",
            "      BatchNorm2d-18           [-1, 32, 32, 32]              64\n",
            "            Block-19           [-1, 32, 32, 32]               0\n",
            "           Conv2d-20           [-1, 32, 16, 16]             288\n",
            "      BatchNorm2d-21           [-1, 32, 16, 16]              64\n",
            "           Conv2d-22           [-1, 64, 16, 16]           2,048\n",
            "      BatchNorm2d-23           [-1, 64, 16, 16]             128\n",
            "           Conv2d-24           [-1, 64, 16, 16]           2,048\n",
            "      BatchNorm2d-25           [-1, 64, 16, 16]             128\n",
            "            Block-26           [-1, 64, 16, 16]               0\n",
            "           Conv2d-27           [-1, 64, 16, 16]             576\n",
            "      BatchNorm2d-28           [-1, 64, 16, 16]             128\n",
            "           Conv2d-29           [-1, 64, 16, 16]           4,096\n",
            "      BatchNorm2d-30           [-1, 64, 16, 16]             128\n",
            "            Block-31           [-1, 64, 16, 16]               0\n",
            "           Conv2d-32           [-1, 64, 16, 16]             576\n",
            "      BatchNorm2d-33           [-1, 64, 16, 16]             128\n",
            "           Conv2d-34           [-1, 64, 16, 16]           4,096\n",
            "      BatchNorm2d-35           [-1, 64, 16, 16]             128\n",
            "            Block-36           [-1, 64, 16, 16]               0\n",
            "           Conv2d-37           [-1, 64, 16, 16]             576\n",
            "      BatchNorm2d-38           [-1, 64, 16, 16]             128\n",
            "           Conv2d-39           [-1, 64, 16, 16]           4,096\n",
            "      BatchNorm2d-40           [-1, 64, 16, 16]             128\n",
            "            Block-41           [-1, 64, 16, 16]               0\n",
            "           Conv2d-42             [-1, 64, 8, 8]             576\n",
            "      BatchNorm2d-43             [-1, 64, 8, 8]             128\n",
            "           Conv2d-44            [-1, 128, 8, 8]           8,192\n",
            "      BatchNorm2d-45            [-1, 128, 8, 8]             256\n",
            "           Conv2d-46            [-1, 128, 8, 8]           8,192\n",
            "      BatchNorm2d-47            [-1, 128, 8, 8]             256\n",
            "            Block-48            [-1, 128, 8, 8]               0\n",
            "           Conv2d-49            [-1, 128, 8, 8]           1,152\n",
            "      BatchNorm2d-50            [-1, 128, 8, 8]             256\n",
            "           Conv2d-51            [-1, 128, 8, 8]          16,384\n",
            "      BatchNorm2d-52            [-1, 128, 8, 8]             256\n",
            "            Block-53            [-1, 128, 8, 8]               0\n",
            "           Conv2d-54            [-1, 128, 8, 8]           1,152\n",
            "      BatchNorm2d-55            [-1, 128, 8, 8]             256\n",
            "           Conv2d-56            [-1, 128, 8, 8]          16,384\n",
            "      BatchNorm2d-57            [-1, 128, 8, 8]             256\n",
            "            Block-58            [-1, 128, 8, 8]               0\n",
            "           Conv2d-59            [-1, 128, 8, 8]           1,152\n",
            "      BatchNorm2d-60            [-1, 128, 8, 8]             256\n",
            "           Conv2d-61            [-1, 128, 8, 8]          16,384\n",
            "      BatchNorm2d-62            [-1, 128, 8, 8]             256\n",
            "            Block-63            [-1, 128, 8, 8]               0\n",
            "           Conv2d-64            [-1, 128, 8, 8]           1,152\n",
            "      BatchNorm2d-65            [-1, 128, 8, 8]             256\n",
            "           Conv2d-66            [-1, 128, 8, 8]          16,384\n",
            "      BatchNorm2d-67            [-1, 128, 8, 8]             256\n",
            "            Block-68            [-1, 128, 8, 8]               0\n",
            "           Conv2d-69            [-1, 128, 8, 8]           1,152\n",
            "      BatchNorm2d-70            [-1, 128, 8, 8]             256\n",
            "           Conv2d-71            [-1, 128, 8, 8]          16,384\n",
            "      BatchNorm2d-72            [-1, 128, 8, 8]             256\n",
            "            Block-73            [-1, 128, 8, 8]               0\n",
            "           Conv2d-74            [-1, 128, 8, 8]           1,152\n",
            "      BatchNorm2d-75            [-1, 128, 8, 8]             256\n",
            "           Conv2d-76            [-1, 128, 8, 8]          16,384\n",
            "      BatchNorm2d-77            [-1, 128, 8, 8]             256\n",
            "            Block-78            [-1, 128, 8, 8]               0\n",
            "           Conv2d-79            [-1, 128, 8, 8]           1,152\n",
            "      BatchNorm2d-80            [-1, 128, 8, 8]             256\n",
            "           Conv2d-81            [-1, 128, 8, 8]          16,384\n",
            "      BatchNorm2d-82            [-1, 128, 8, 8]             256\n",
            "            Block-83            [-1, 128, 8, 8]               0\n",
            "           Conv2d-84            [-1, 128, 8, 8]           1,152\n",
            "      BatchNorm2d-85            [-1, 128, 8, 8]             256\n",
            "           Conv2d-86            [-1, 128, 8, 8]          16,384\n",
            "      BatchNorm2d-87            [-1, 128, 8, 8]             256\n",
            "            Block-88            [-1, 128, 8, 8]               0\n",
            "           Conv2d-89            [-1, 128, 4, 4]           1,152\n",
            "      BatchNorm2d-90            [-1, 128, 4, 4]             256\n",
            "           Conv2d-91            [-1, 256, 4, 4]          32,768\n",
            "      BatchNorm2d-92            [-1, 256, 4, 4]             512\n",
            "           Conv2d-93            [-1, 256, 4, 4]          32,768\n",
            "      BatchNorm2d-94            [-1, 256, 4, 4]             512\n",
            "            Block-95            [-1, 256, 4, 4]               0\n",
            "           Conv2d-96            [-1, 256, 4, 4]           2,304\n",
            "      BatchNorm2d-97            [-1, 256, 4, 4]             512\n",
            "           Conv2d-98            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-99            [-1, 256, 4, 4]             512\n",
            "           Block-100            [-1, 256, 4, 4]               0\n",
            "          Conv2d-101            [-1, 256, 4, 4]           2,304\n",
            "     BatchNorm2d-102            [-1, 256, 4, 4]             512\n",
            "          Conv2d-103            [-1, 256, 4, 4]          65,536\n",
            "     BatchNorm2d-104            [-1, 256, 4, 4]             512\n",
            "           Block-105            [-1, 256, 4, 4]               0\n",
            "          Conv2d-106            [-1, 256, 4, 4]           2,304\n",
            "     BatchNorm2d-107            [-1, 256, 4, 4]             512\n",
            "          Conv2d-108            [-1, 256, 4, 4]          65,536\n",
            "     BatchNorm2d-109            [-1, 256, 4, 4]             512\n",
            "           Block-110            [-1, 256, 4, 4]               0\n",
            "          Conv2d-111            [-1, 256, 2, 2]           2,304\n",
            "     BatchNorm2d-112            [-1, 256, 2, 2]             512\n",
            "          Conv2d-113            [-1, 512, 2, 2]         131,072\n",
            "     BatchNorm2d-114            [-1, 512, 2, 2]           1,024\n",
            "          Conv2d-115            [-1, 512, 2, 2]         131,072\n",
            "     BatchNorm2d-116            [-1, 512, 2, 2]           1,024\n",
            "           Block-117            [-1, 512, 2, 2]               0\n",
            "          Conv2d-118            [-1, 512, 2, 2]           4,608\n",
            "     BatchNorm2d-119            [-1, 512, 2, 2]           1,024\n",
            "          Conv2d-120            [-1, 512, 2, 2]         262,144\n",
            "     BatchNorm2d-121            [-1, 512, 2, 2]           1,024\n",
            "           Block-122            [-1, 512, 2, 2]               0\n",
            "         Dropout-123                  [-1, 512]               0\n",
            "          Linear-124                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 1,001,642\n",
            "Trainable params: 1,001,642\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 10.58\n",
            "Params size (MB): 3.82\n",
            "Estimated Total Size (MB): 14.41\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.randn(1, 3, 32, 32).to(device)\n",
        "\n",
        "flops = FlopCountAnalysis(model, inputs)\n",
        "print('Total FLOPS :', flops.total())  # Total FLOPS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnEuoogNTrj-",
        "outputId": "9c54f6ce-51db-45ed-e84a-d701fb1e7ac2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add encountered 22 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::avg_pool2d encountered 1 time(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total FLOPS : 26681344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "model = CustomMobileNet().to(device)\n",
        "\n",
        "model_path = '/content/MobileNetV1-Optimization-for-CIFAR10/best_weights/CustomMobileNet_best_model_epoch_95.pkt'\n",
        "model.load_state_dict(torch.load(model_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fhf_S123TN7D",
        "outputId": "19245efe-fe4e-4886-c499-d250f54bc4f9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_loss, correct, total = 0, 0, 0\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)\n",
        "with torch.no_grad():  #using context manager\n",
        "    for images, labels in test_loader :\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        output = model(images)\n",
        "        test_loss += loss_function(output, labels).item()\n",
        "\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "\n",
        "        total += labels.size(0)\n",
        "\n",
        "print('[Test set] Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss /total, correct, total,\n",
        "        100. * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foXciIv3TTCa",
        "outputId": "5a91db51-2d90-457e-a98a-e592b70d23b7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Test set] Average loss: 0.0032, Accuracy: 9181/10000 (91.81%)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}